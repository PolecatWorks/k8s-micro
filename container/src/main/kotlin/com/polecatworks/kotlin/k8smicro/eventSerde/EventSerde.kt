package com.polecatworks.kotlin.k8smicro.eventSerde

import io.confluent.kafka.schemaregistry.client.SchemaRegistryClient
import kotlinx.io.Buffer
import kotlinx.serialization.ExperimentalSerializationApi
import org.apache.kafka.common.serialization.Deserializer
import org.apache.kafka.common.serialization.Serde
import org.apache.kafka.common.serialization.Serializer
import java.io.ByteArrayOutputStream

class EventSerde<T : Any>(
    private val schemaRegistryClient: SchemaRegistryClient,
    private val isKey: Boolean,
    private val topic: String
): Serde<T> {

    companion object {
        const val MAGIC_BYTE: Byte = 0x0
        const val SCHEMA_ID_SIZE = 4
    }

    private val avro4kSerializer = Serializer<T> { _, data ->
        if (data == null) return@Serializer null


        val baos = ByteArrayOutputStream()

        baos.toByteArray()
    }

    @OptIn(ExperimentalSerializationApi::class)
    private val avro4kDeserializer = Deserializer<T> { topic, data: ByteArray? ->
        if (data == null) return@Deserializer null

        try {


            val buffer = Buffer()
            buffer.write(data)

            // Check magic byte
            val magicByte = buffer.readByte()
            if (magicByte != MAGIC_BYTE) {
                throw IllegalArgumentException("Invalid magic byte: $magicByte")
            }

            val schemaId = buffer.readInt()

            val schema = schemaRegistryClient.getById(schemaId)
//            val avroData = ByteArray(buffer.remaining())
//            buffer.get(avroData)


//            // Deserialize using Avro
//            val genericRecord = org.apache.avro.io.DecoderFactory.get().let { factory ->
//                val input = java.io.ByteArrayInputStream(avroData)
//                val decoder = factory.binaryDecoder(input, null)
//                val reader = org.apache.avro.generic.GenericDatumReader<GenericRecord>(schema)
//                reader.read(null, decoder)
//            }

//            return deserializer(genericRecord)
            null
        } catch (e: Exception) {
            throw RuntimeException("Failed to deserialize", e)
        }
    }




    // The Avro schema for the data class, generated by avro4k
//    private val avroSchema = Avro.schema<T>()

    // The subject name in the Schema Registry
    private val subject = if (isKey) "$topic-key" else "$topic-value"
    private var schemaId: Int? = null
    override fun serializer(): Serializer<T> = avro4kSerializer
    override fun deserializer(): Deserializer<T> = avro4kDeserializer

    // A simple Avro4k Serializer implementation
//    private val avro4kSerializer = Serializer<T> { _, data ->
//        if (data == null) return@Serializer null
//
//        // Use a cached schema ID if available, otherwise register the schema.
//        val currentSchemaId = schemaId ?: try {
//            schemaRegistryClient.register(subject, avroSchema).also { schemaId = it }
//        } catch (e: RestClientException) {
//            // In case of error (e.g., schema already registered), fetch the ID.
//            schemaRegistryClient.getId(subject, avroSchema)
//        }
//
//        // Use a ByteArrayOutputStream to write the data.
//        val baos = ByteArrayOutputStream()
//
//        // Write the Confluent-specific magic byte (0x00) and the 4-byte schema ID.
//        baos.write(0x00)
//        baos.write(ByteBuffer.allocate(4).putInt(currentSchemaId).array())
//
//        // Use avro4k to write the actual Avro data.
//        AvroOutputStream.avro(avroSchema).to(baos).build().use { output ->
//            output.write(data)
//        }
//        baos.toByteArray()
//    }

    // A simple Avro4k Deserializer implementation
//    private val avro4kDeserializer = Deserializer<T> { _, bytes ->
//        if (bytes == null) return@Deserializer null
//
//        // Read the Confluent-specific magic byte and the 4-byte schema ID.
//        val buffer = ByteBuffer.wrap(bytes)
//        if (buffer.get() != 0x00.toByte()) {
//            throw IllegalArgumentException("Unknown magic byte!")
//        }
//        val currentSchemaId = buffer.getInt()
//
//        // Fetch the schema from the Schema Registry using the ID.
//        val schema = schemaRegistryClient.getSchemaById(currentSchemaId)
//
//        // Read the remaining bytes, which contain the Avro data.
//        val avroBytes = ByteArray(buffer.remaining())
//        buffer.get(avroBytes)
//
//        // Use avro4k to deserialize the data using the fetched schema.
//        val bais = ByteArrayInputStream(avroBytes)
//        AvroInputStream.avro(schema).from(bais).build().use { input ->
//            input.nextOrThrow()
//        }
//    }

//    override fun configure(configs: Map<String, *>, isKey: Boolean) {
//        // No-op, configuration is handled in the constructor
//    }
//
//    override fun close() {
//        // No-op for this simple Serde
//    }
//
//    override fun serializer(): Serializer<T> = avro4kSerializer
//
//    override fun deserializer(): Deserializer<T> = avro4kDeserializer
}
